# Comparison between classification models
1. Decision Tree
2. Support Vector Machine
3. Logistic Regression
4. Naive Bayes

# Dataset : 
https://www.kaggle.com/datasets/arshid/iris-flower-dataset

# Description
This repository provides an analysis of four popular classification models: Decision Tree, Support Vector Machine (SVM), Logistic Regression, and Naive Bayes. The performance of these models was evaluated on a dataset, considering metrics such as accuracy, precision, recall, and ROC AUC. The comparison aims to provide insights into the strengths and weaknesses of each model, aiding in the selection of an appropriate classification approach for specific tasks. The analysis can serve as a valuable resource for practitioners and researchers in the field of machine learning and data analysis

# Conclusion
The Decision Tree algorithm achieved an accuracy of 93.33%, while the SVM, Logistic Regression, and Naive Bayes algorithms all achieved an accuracy of 95.56%. These results indicate that all four algorithms performed well in classifying the data.

Moreover, the precision, recall, and ROC AUC scores were consistently high across all algorithms, ranging from 93.61% to 96.08% for precision, recall, and ROC AUC. This suggests that the algorithms were effective in both minimizing false positives and false negatives and accurately identifying positive instances.

In conclusion, the SVM, Logistic Regression, and Naive Bayes algorithms demonstrated slightly better performance compared to the Decision Tree algorithm, with an accuracy of 95.56%. These algorithms exhibited high precision, recall, and ROC AUC scores, indicating their effectiveness in classification tasks.
